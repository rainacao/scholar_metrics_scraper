{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb8d362-d38b-41b1-9894-7755e19975bd",
   "metadata": {},
   "source": [
    "![DBC](Images/DBC.png)\n",
    "\n",
    "# ScholarScraper\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "This script automates the process of scraping this information from Google Scholar for a list of authors. It utilizes [scholarly](https://pypi.org/project/scholarly/), a Python module that allows users to retrieve bibliometrics from [Google Scholar](https://scholar.google.ca/).\n",
    "\n",
    "This project currently works with scholarly 1.4.5\n",
    "\n",
    "**Installation and Setup**\n",
    "\n",
    "1. Set-up Jupyter. If your institution has access, you can use [Syzygy](https://syzygy.ca/) to run in the Cloud, or install on your computer following [these instructions](https://jupyter.org/install).\n",
    "2. Clone the project.\n",
    "    - Open Terminal (in Syzygy, click the \"+\" button to open a new launcher and click \"Terminal\"\n",
    "    - Type  \"git clone https://github.com/ubcbraincircuits/ScholarScraper\" and press enter\n",
    "    - The project should now be cloned in your directory. \n",
    "    - Alternatively, you can download the project as a ZIP file from https://github.com/ubcbraincircuits/ScholarScraper (click Code, then Download ZIP)\n",
    "3. [Install scholarly](https://pypi.org/project/scholarly/)\n",
    "    - In the terminal (from above) type \"pip install scholarly\" and press enter\n",
    "4. Obtain a CSV file with the list of author names in a single column with no column header. Ideally, all author names should match their names in Google Scholar. Upload this file to Syzygy or move it to the project folder on your computer. This file should be in the same directory as this notebook file (ScholarScraper.ipynb). \n",
    "5. Modify the names of the input/output files below (in step 1). The input file name must match the CSV file name. \n",
    "6. Modify the \"affiliations\" variable as a list of institution names which the researchers are affiliated with. Include both abbreviated and long form.  \n",
    "7. Run all cells (click shift+enter to run a cell or the play button above). \n",
    "8. Open the ouput CSV file in the same directory as this notebook file. Check the last column of this file for warnings. If needed, modify the author names in the input CSV file if the wrong author profile was scraped, or no profile was found, and re-run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332df0dc-a0ad-4946-a11b-7ea1813766ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly\n",
    "import csv\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8296e4-0796-48c1-b4c7-a72cefac5dab",
   "metadata": {},
   "source": [
    "1. **Modify** the names of the input and output files. The name of the input file should match the name of the author list CSV file. If you followed the setup instructions, the CSV file should now be in the same directory as this notebook file. The output file does not have to exist yet (it will be created). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1637768d-85ae-4f31-9af7-7f9c890eb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_authors = 'DBC Investigators.csv'\n",
    "output_data = 'ss_output_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356ce131-3f1c-48a8-98fb-0130f871aa29",
   "metadata": {},
   "source": [
    "2. Load in the author names from the CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cc98e7-2e5f-47ed-a354-0cf2e471c5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_names= []\n",
    "with open(input_authors, encoding =\"utf-8-sig\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter =',')\n",
    "    for row in csv_reader:\n",
    "        if (len(row) == 1):\n",
    "            author_names.append(row[0])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1fe16-1611-481e-9a1f-002db9385962",
   "metadata": {},
   "source": [
    "3. **Specify** the institution which the researchers are affiliated with. Tip: include long and abbreviated versions of institution names. Remember to use quotations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb73535e-9cd7-4977-ae10-939aa00d63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliations = [\"University of British Columbia\", \"UBC\", \"Djavad Mowafaghian\", \"Simon Fraser University\",\n",
    "                \"University of Victoria\", \"University of Washington\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998bb632-871c-420f-9388-0b2366493e32",
   "metadata": {},
   "source": [
    "4. Scrape data for each author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ed9c40e-4e68-4f38-9130-b1d6059bd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will contain all the data for each author which will be exported as a table. It will be a list of dictionaries. \n",
    "rows = []\n",
    "# This will contain a list of dictionaries for each author. The dictionaries will be made up of years as keys and citation numbers as vals\n",
    "cites_per_year = []\n",
    "# This dictionary will contain publication titles as keys and author names as values\n",
    "pub_authors = {}\n",
    "\n",
    "\n",
    "for i, athr in enumerate(author_names):\n",
    "    pubs = []\n",
    "    search_query = scholarly.search_author(athr)\n",
    "    try :\n",
    "        author = next(search_query)\n",
    "    except (RuntimeError,TypeError,StopIteration):\n",
    "        row = {'Name': athr, 'Warning': 'no information found'}\n",
    "    else:\n",
    "        data_dict = scholarly.fill(author, sections=['basics', 'indices', 'publications', 'counts'])\n",
    "        \n",
    "        # Get publications. Add titles to dataframe and add authors to pub_authors dictionary\n",
    "        for pub in data_dict['publications']:\n",
    "            pubs.append(pub['bib']['title'])\n",
    "            pub_authors.setdefault(pub['bib']['title'],[]).append(data_dict['name'])\n",
    "        \n",
    "        # Get citations per year and put in dictionary\n",
    "        cites_per_year_dict = data_dict['cites_per_year']\n",
    "        # Add name to dictionary \n",
    "        cites_per_year_dict['name'] = data_dict['name']\n",
    "        cites_per_year.append(cites_per_year_dict)\n",
    "        \n",
    "        # Create row (dictionary) for output data table\n",
    "        row = {'Name': data_dict['name'], 'Scholar ID': data_dict['scholar_id'], \n",
    "               'Cited by': data_dict['citedby'], 'Cited by 5 years': data_dict['citedby5y'], \n",
    "               'h-index': data_dict['hindex'], 'h-index 5 years': data_dict['hindex5y'], \n",
    "               'i10-index': data_dict['i10index'],'i10-index 5 years': data_dict['i10index5y'], \n",
    "               'Publications': pubs, 'Affiliation': data_dict['affiliation']}\n",
    "        \n",
    "        # Create list of authors who do not have the specified affiliation\n",
    "        if not any(a in data_dict['affiliation'] for a in affiliations):\n",
    "            row['Warning'] = \"Affiliation does not match!\"\n",
    "            \n",
    "    finally:    \n",
    "        rows.append(row)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b39653-cbbf-4fa7-81f2-a50d7b33c609",
   "metadata": {},
   "source": [
    "5. Add coauthors to the rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20cea894-1389-42b5-a718-b282dff645e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dictionary with author names as keys and dictionary (coauthor name as key, number of collaborations as value) \n",
    "#   as value\n",
    "collabs_dict={}\n",
    "for key in pub_authors:\n",
    "    for author in pub_authors[key]:\n",
    "        for coauthor in pub_authors[key]:\n",
    "            if coauthor is not author:\n",
    "                if author not in collabs_dict.keys() or coauthor not in collabs_dict[author].keys():\n",
    "                    collabs_dict.setdefault(author,{})[coauthor]=1\n",
    "                else:\n",
    "                    collabs_dict[author][coauthor]+=1\n",
    "\n",
    "\n",
    "# Write to rows dataframe\n",
    "for row in rows:\n",
    "    if row['Name'] in collabs_dict.keys():\n",
    "        row['Coauthors'] = collabs_dict[row['Name']]\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff719ca3-a2b3-4b62-bc57-58ae9913f521",
   "metadata": {},
   "source": [
    "6. Write rows to output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "765aa4c8-9e4c-45da-a8ff-f7bfddd3a287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the order of the data. These keys must match the names of the keys in the rows dictionary. \n",
    "keys = ['Name', 'Scholar ID', 'Cited by', 'Cited by 5 years', 'h-index', 'h-index 5 years',  'i10-index', 'i10-index 5 years', 'Publications', 'Coauthors', 'Affiliation', 'Warning']\n",
    "\n",
    "# This creates/opens the file with filename with the intention to write to the csv_file\n",
    "# The encoding allows the characters to be properly written to the csv_file\n",
    "with open(output_data, mode='w', encoding =\"utf-8\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    dict_writer = csv.DictWriter(csv_file, keys, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a406e-0384-45ed-b7f1-505458c4eeb2",
   "metadata": {},
   "source": [
    "7. Create barplot of citations per year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd757b95-ddaa-46f4-b29a-c362813ded23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create citations per year dataframe\n",
    "cites_df = pd.DataFrame(cites_per_year)\n",
    "\n",
    "# Add a totals column\n",
    "cites_df.loc['Total']= cites_df.sum()\n",
    "\n",
    "# Select years to plot\n",
    "cites_df_selected = cites_df[[2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021]]\n",
    "\n",
    "# Select the last row (totals) \n",
    "cites_df_total = cites_df_selected.iloc[-1:]\n",
    "\n",
    "# Create barplot\n",
    "years = list(cites_df_total.columns)\n",
    "cites = cites_df_total.values.tolist()[0]\n",
    "plt.bar(years, cites )\n",
    "plt.ylabel('Total Citations')\n",
    "plt.savefig(\"citations.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

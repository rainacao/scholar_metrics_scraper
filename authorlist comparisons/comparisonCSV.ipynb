{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d72bc6-60c9-4877-b597-0566229d982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127f5bf5de20d338f686704a9a328b86\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, ast\n",
    "import csv\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from pybliometrics.scopus import CitationOverview, AuthorRetrieval, AbstractRetrieval\n",
    "from pybliometrics.scopus.utils import config\n",
    "config['Authentication'] ['APIKey'] = \"127f5bf5de20d338f686704a9a328b86\"\n",
    "print(config['Authentication'] ['APIKey'])\n",
    "import bct\n",
    "from scholarly import scholarly, ProxyGenerator\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a23163e-670f-4469-9fec-4fdab2d88cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthor_matrix(df):\n",
    "    names = df.loc[:,\"Name\"]\n",
    "    coauthor_matrix = np.zeros((names.size, names.size))\n",
    "\n",
    "    for idx, author in df.iterrows():\n",
    "        auth_name = author[\"Name\"]\n",
    "        row = names[names == auth_name].index[0]\n",
    "        try:\n",
    "            coauthors = ast.literal_eval(author[\"Coauthors\"]) #get coauthors\n",
    "            if len(coauthors) == 0: print(auth_name, \"has no coauthors\")\n",
    "            for coauthor in coauthors.keys():\n",
    "                num_publications = coauthors[coauthor]\n",
    "                col = names[names == coauthor].index[0]\n",
    "                coauthor_matrix[col][row] += num_publications\n",
    "\n",
    "        except:\n",
    "            print(auth_name, \"has no coauthors\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    return coauthor_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d78ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_details(author_row, sv_df, gs_df) -> dict:\n",
    "    \n",
    "    #get scopus profile\n",
    "    sv_name = sv_df.at[author_row,\"Name\"]\n",
    "    sv_id = sv_df.at[author_row,\"Scopus ID\"]\n",
    "    sv_coauthors = sv_df.at[author_row,\"Coauthors\"]\n",
    "    ar = AuthorRetrieval(sv_id)\n",
    "    pubs = ar.get_documents()\n",
    "    \n",
    "    #get scopus publications\n",
    "    sv_titles = []\n",
    "    for pub in pubs:\n",
    "        sv_titles.append(pub.title)\n",
    "\n",
    "    #get gs profile\n",
    "    gs_name = gs_df.at[author_row,\"Name\"]\n",
    "    gs_id = gs_df.at[author_row,\"Scholar ID\"]\n",
    "    gs_coauthors = gs_df.at[author_row,\"Coauthors\"]\n",
    "    pg = ProxyGenerator()\n",
    "    success = pg.FreeProxies()\n",
    "    scholarly.use_proxy(pg)\n",
    "    author = scholarly.search_author_id(gs_id)\n",
    "\n",
    "    #get gs publications\n",
    "    gs_titles = []\n",
    "    data_dict = scholarly.fill(author, sections=['basics', 'indices', 'publications', 'counts'])\n",
    "\n",
    "    for pub in data_dict['publications']:\n",
    "        gs_titles.append(pub['bib']['title'])\n",
    "\n",
    "    #clean titles\n",
    "    sv_titles = [\n",
    "        title.replace(\"<sup>\",\"\").replace(\"</sup>\",\"\").replace(\"<inf>\",\"\").replace(\"</inf>\",\"\") \n",
    "        for title in sv_titles\n",
    "    ]\n",
    "        #clean\n",
    "    sv_titles = [\n",
    "        \" \".join(\n",
    "            [\n",
    "                word.strip() \n",
    "                for word in re.sub(r'[^\\w]', ' ', title.lower()).split(\" \") \n",
    "                if word != \"\"])\n",
    "        for title in sv_titles\n",
    "        ]\n",
    "    # gs_titles_lowered = [re.sub(r'[^\\w]', ' ', title.lower()).strip() for title in gs_titles]\n",
    "    gs_titles = [\n",
    "        \" \".join(\n",
    "            [\n",
    "                word.strip() \n",
    "                for word in re.sub(r'[^\\w]', ' ', title.lower()).split(\" \") \n",
    "                if word != \"\"])\n",
    "        for title in gs_titles\n",
    "        ]\n",
    "\n",
    "    total_gs_pubs = len(gs_titles)\n",
    "    total_sv_pubs = len(sv_titles)\n",
    "\n",
    "    #duplicates (only number of duplicated titles)\n",
    "    sv_duplicate_titles = [k for k,v in Counter(sv_titles).items() if v>1] \n",
    "    gs_duplicate_titles = [k for k,v in Counter(gs_titles).items() if v>1]\n",
    "\n",
    "    #accounts for multiple duplicates\n",
    "    sv_items = defaultdict(list)\n",
    "    for i,item in enumerate(sv_titles):\n",
    "        sv_items[item].append(i)\n",
    "    sv_duplicates = {k:v for k,v in sv_items.items() if len(v)>1}\n",
    "    sv_num_duplicates = sum(np.array([len(v) for k,v in sv_duplicates.items()]))\n",
    "    sv_unique = {k:v for k,v in sv_items.items() if len(v)==1}\n",
    "    sv_num_unique = sum(np.array([len(v) for k,v in sv_unique.items()]))\n",
    "    \n",
    "    gs_items = defaultdict(list)\n",
    "    for i,item in enumerate(gs_titles):\n",
    "        gs_items[item].append(i)\n",
    "    gs_duplicates = {k:v for k,v in gs_items.items() if len(v)>1}\n",
    "    gs_num_duplicates = sum(np.array([len(v) for k,v in gs_duplicates.items()]))\n",
    "    gs_unique = {k:v for k,v in gs_items.items() if len(v)==1}\n",
    "    gs_num_unique = sum(np.array([len(v) for k,v in gs_unique.items()]))\n",
    "\n",
    "    #matching titles\n",
    "    shared_titles = list(set(gs_titles).intersection(sv_titles))\n",
    "    num_matches = len(shared_titles)\n",
    "    shared_str = ''\n",
    "    for title in shared_titles:\n",
    "        shared_str = title + \"\\n\" + shared_str\n",
    "\n",
    "    #only sv\n",
    "    sv_only_titles = list(set(sv_titles) - set(gs_titles))\n",
    "    sv_only_str = ''\n",
    "    for title in sv_only_titles:\n",
    "        sv_only_str = title + \"\\n\" + sv_only_str\n",
    "    num_sv_only = len(sv_only_titles)\n",
    "\n",
    "    #only gs\n",
    "    gs_only_titles = list(set(gs_titles) - set(sv_titles))\n",
    "    gs_only_str = ''\n",
    "    for title in gs_only_titles:\n",
    "        gs_only_str = title + \"\\n\" + gs_only_str\n",
    "    num_gs_only = len(gs_only_titles)\n",
    "\n",
    "    author_dict = {\n",
    "        'sv_name': sv_name, \n",
    "        'sv_id': sv_id,\n",
    "        'gs_name': gs_name, \n",
    "        'gs_id': gs_id,\n",
    "        'gs_count': total_gs_pubs, \n",
    "        'gs_num_duplicates': gs_num_duplicates,\n",
    "        'gs_duplicate_titles': gs_duplicate_titles,\n",
    "        'gs_num_unique': gs_num_unique,\n",
    "        'sv_count': total_sv_pubs, \n",
    "        'sv_num_duplicates': sv_num_duplicates,\n",
    "        'sv_duplicate_titles': sv_duplicate_titles,\n",
    "        'sv_num_unique': sv_num_unique,\n",
    "        'gs_only_count':num_gs_only, \n",
    "        'sv_only_count':num_sv_only,\n",
    "        'shared_count':num_matches,\n",
    "        'gs_coauthors':gs_coauthors,\n",
    "        'sv_coauthors':sv_coauthors,\n",
    "        'gs_betweenness_centrality_normed': \"\",\n",
    "        'sv_betweenness_centrality_normed': \"\",\n",
    "        '\"sv_duplicates\"':sv_duplicates,\n",
    "        '\"gs_duplicates\"':gs_duplicates,\n",
    "        # 'gs_only_pubs':gs_only_str,\n",
    "        # 'sv_only_pubs':sv_only_str,\n",
    "        # 'shared_pubs':shared_str,\n",
    "    }\n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc07d91",
   "metadata": {},
   "source": [
    "# 1. read from csvs containing author and coauthor information in a dict format to do matrix analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9b5b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annie Vogel Ciernia has no coauthors\n",
      "Mark S. Cembrowski has no coauthors\n",
      "Michael D. Gordon has no coauthors\n",
      "Manu S. Madhav has no coauthors\n",
      "Brian Fisher has no coauthors\n",
      "Emily Lauren Sylwestrak has no coauthors\n",
      "Anthony Randal McIntosh has no coauthors\n",
      "\n",
      "\n",
      "Michael Gordon has no coauthors\n",
      "Manu S Madhav has no coauthors\n",
      "Emily Sylwestrak has no coauthors\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# author_row = 6\n",
    "\n",
    "sv_df = pd.read_csv(\"scival_outputs/sv_authorlist_publications_updated2.csv\")\n",
    "gs_df = pd.read_csv(\"gs_outputs/gs_authorlist_updated1.csv\")\n",
    "\n",
    "sv_coauthor_matrix = get_coauthor_matrix(sv_df)\n",
    "gs_coauthor_matrix = get_coauthor_matrix(gs_df)\n",
    "\n",
    "sv_betweenness = bct.betweenness_bin(sv_coauthor_matrix)\n",
    "sv_betweenness_normed = sv_betweenness/(((len(sv_coauthor_matrix)-1)*(len(sv_coauthor_matrix)-2))/2)\n",
    "\n",
    "gs_betweenness = bct.betweenness_bin(gs_coauthor_matrix)\n",
    "gs_betweenness_normed = gs_betweenness/(((len(gs_coauthor_matrix)-1)*(len(gs_coauthor_matrix)-2))/2)\n",
    "\n",
    "gs_degrees = bct.degrees_und(gs_coauthor_matrix)\n",
    "sv_degrees = bct.degrees_und(sv_coauthor_matrix)\n",
    "\n",
    "gs_strengths = bct.strengths_und(gs_coauthor_matrix)\n",
    "sv_strengths = bct.strengths_und(sv_coauthor_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27b65af",
   "metadata": {},
   "source": [
    "# 2. process each author in the sv and gs dataframes-- must make sure the author order is the same!!!\n",
    "obtain the dataframe publication details by running scholarscraper and scival_profile_lookup and then scival_publications jupyter notebooks on the same document of input author names (making manual overrides for specific profiles as necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13c11f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\_scholarly.py:312: DeprecationWarning: invalid escape sequence '\\d'\n",
      "  m = re.search(\"cites=[\\d+,]*\", object[\"citedby_url\"])\n"
     ]
    },
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMaxTriesExceededException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dict_list \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sv_df\u001b[39m.\u001b[39mindex)):\n\u001b[1;32m----> 3\u001b[0m     author_dict \u001b[39m=\u001b[39m get_publication_details(row, sv_df, gs_df)\n\u001b[0;32m      4\u001b[0m     author_dict[\u001b[39m'\u001b[39m\u001b[39mgs_betweenness_centrality\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m gs_betweenness[row]\n\u001b[0;32m      5\u001b[0m     author_dict[\u001b[39m'\u001b[39m\u001b[39msv_betweenness_centrality\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sv_betweenness[row]\n",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m, in \u001b[0;36mget_publication_details\u001b[1;34m(author_row, sv_df, gs_df)\u001b[0m\n\u001b[0;32m     20\u001b[0m success \u001b[39m=\u001b[39m pg\u001b[39m.\u001b[39mFreeProxies()\n\u001b[0;32m     21\u001b[0m scholarly\u001b[39m.\u001b[39muse_proxy(pg)\n\u001b[1;32m---> 22\u001b[0m author \u001b[39m=\u001b[39m scholarly\u001b[39m.\u001b[39;49msearch_author_id(gs_id)\n\u001b[0;32m     24\u001b[0m \u001b[39m#get gs publications\u001b[39;00m\n\u001b[0;32m     25\u001b[0m gs_titles \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\_scholarly.py:349\u001b[0m, in \u001b[0;36m_Scholarly.search_author_id\u001b[1;34m(self, id, filled, sortby, publication_limit)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msearch_author_id\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mid\u001b[39m: \u001b[39mstr\u001b[39m, filled: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, sortby: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcitedby\u001b[39m\u001b[39m\"\u001b[39m, publication_limit: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39mAuthor:\n\u001b[0;32m    323\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search by author id and return a single Author object\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[39m    :param sortby: select the order of the citations in the author page. Either by 'citedby' or 'year'. Defaults to 'citedby'.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[39m    :type sortby: string\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39m             'url_picture': 'https://scholar.googleusercontent.com/citations?view_op=view_photo&user=EmD_lTEAAAAJ&citpid=3'}\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__nav\u001b[39m.\u001b[39;49msearch_author_id(\u001b[39mid\u001b[39;49m, filled, sortby, publication_limit)\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\_navigator.py:316\u001b[0m, in \u001b[0;36mNavigator.search_author_id\u001b[1;34m(self, id, filled, sortby, publication_limit)\u001b[0m\n\u001b[0;32m    314\u001b[0m     res \u001b[39m=\u001b[39m author_parser\u001b[39m.\u001b[39mfill(res, sortby\u001b[39m=\u001b[39msortby, publication_limit\u001b[39m=\u001b[39mpublication_limit)\n\u001b[0;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     res \u001b[39m=\u001b[39m author_parser\u001b[39m.\u001b[39;49mfill(res, sections\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mbasics\u001b[39;49m\u001b[39m'\u001b[39;49m], sortby\u001b[39m=\u001b[39;49msortby, publication_limit\u001b[39m=\u001b[39;49mpublication_limit)\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\author_parser.py:462\u001b[0m, in \u001b[0;36mAuthorParser.fill\u001b[1;34m(self, author, sections, sortby, publication_limit)\u001b[0m\n\u001b[0;32m    460\u001b[0m                 author[\u001b[39m'\u001b[39m\u001b[39mfilled\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m    461\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 462\u001b[0m     \u001b[39mraise\u001b[39;00m(e)\n\u001b[0;32m    464\u001b[0m \u001b[39mreturn\u001b[39;00m author\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\author_parser.py:441\u001b[0m, in \u001b[0;36mAuthorParser.fill\u001b[1;34m(self, author, sections, sortby, publication_limit)\u001b[0m\n\u001b[0;32m    439\u001b[0m url_citations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sortby_str\n\u001b[0;32m    440\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m&pagesize=\u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(url_citations, _PAGESIZE)\n\u001b[1;32m--> 441\u001b[0m soup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnav\u001b[39m.\u001b[39;49m_get_soup(url)\n\u001b[0;32m    443\u001b[0m \u001b[39m# Update scholar_id\u001b[39;00m\n\u001b[0;32m    444\u001b[0m scholar_id \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mfindall(_CITATIONAUTHRE, soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m\"\u001b[39m, rel\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcanonical\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\_navigator.py:239\u001b[0m, in \u001b[0;36mNavigator._get_soup\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_soup\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BeautifulSoup:\n\u001b[0;32m    238\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     html \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_page(\u001b[39m'\u001b[39;49m\u001b[39mhttps://scholar.google.com\u001b[39;49m\u001b[39m{0}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(url))\n\u001b[0;32m    240\u001b[0m     html \u001b[39m=\u001b[39m html\u001b[39m.\u001b[39mreplace(\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\xa0\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     res \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\_navigator.py:188\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[1;34m(self, pagerequest, premium)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[39m# If secondary proxy does not work, try again primary proxy.\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m premium:\n\u001b[1;32m--> 188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_page(pagerequest, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[39mraise\u001b[39;00m MaxTriesExceededException(\u001b[39m\"\u001b[39m\u001b[39mCannot Fetch from Google Scholar.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\scholarly\\_navigator.py:190\u001b[0m, in \u001b[0;36mNavigator._get_page\u001b[1;34m(self, pagerequest, premium)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_page(pagerequest, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mraise\u001b[39;00m MaxTriesExceededException(\u001b[39m\"\u001b[39m\u001b[39mCannot Fetch from Google Scholar.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mMaxTriesExceededException\u001b[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "dict_list = []\n",
    "for row in range(len(sv_df.index)):\n",
    "    author_dict = get_publication_details(row, sv_df, gs_df)\n",
    "    author_dict['gs_betweenness_centrality'] = gs_betweenness[row]\n",
    "    author_dict['sv_betweenness_centrality'] = sv_betweenness[row]\n",
    "    author_dict['gs_betweenness_centrality_normed'] = gs_betweenness_normed[row]\n",
    "    author_dict['sv_betweenness_centrality_normed'] = sv_betweenness_normed[row]\n",
    "    author_dict['gs_degree'] = gs_degrees[row]\n",
    "    author_dict['sv_degree'] = sv_degrees[row]\n",
    "    author_dict['gs_strength'] = gs_strengths[row]\n",
    "    author_dict['sv_strength'] = sv_strengths[row]\n",
    "    dict_list.append(author_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in dict_list:\n",
    "#     gs_num_duplicates = len(d['gs_duplicates_count'])\n",
    "#     sv_num_duplicates = len(d['sv_duplicates_count'])\n",
    "#     sv_num_duplicates = sum(np.array([len(v) for k,v in sv_D.items()]))\n",
    "    \n",
    "#     print(\"total scival duplicates:\",sum(np.array([len(v) for k,v in sv_D.items()])))\n",
    "#     print()\n",
    "\n",
    "#     d.update((k, gs_num_duplicates) for k, v in d.items() if k == \"gs_duplicates_count\")\n",
    "#     d.update((k, sv_num_duplicates) for k, v in d.items() if k == \"sv_duplicates_count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a03a9",
   "metadata": {},
   "source": [
    "# 3. export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0113aaaa-138d-410d-98b6-ae27521eeec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mauthors_comparisons_updated2_complete.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m csv_file:\n\u001b[0;32m      3\u001b[0m     header \u001b[39m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msv_name\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msv_id\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[39m# 'shared_pubs',\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     ]\n",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mauthors_comparisons_updated2_complete.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m csv_file:\n\u001b[0;32m      3\u001b[0m     header \u001b[39m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msv_name\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m         \u001b[39m'\u001b[39m\u001b[39msv_id\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[39m# 'shared_pubs',\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     ]\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caoyut\\.conda\\envs\\sms\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"authors_comparisons_updated2_complete.csv\", \"w\") as csv_file:\n",
    "    header = [\n",
    "        'sv_name', \n",
    "        'sv_id',\n",
    "        'gs_name', \n",
    "        'gs_id',\n",
    "        'gs_count', \n",
    "        'gs_num_duplicates',\n",
    "        'gs_duplicate_titles',\n",
    "        'gs_num_unique',\n",
    "        'sv_count', \n",
    "        'sv_num_duplicates',\n",
    "        'sv_duplicate_titles',\n",
    "        'sv_num_unique',\n",
    "        'gs_only_count', \n",
    "        'sv_only_count',\n",
    "        'shared_count',\n",
    "        'gs_coauthors',\n",
    "        'sv_coauthors',\n",
    "        'gs_betweenness_centrality',\n",
    "        'sv_betweenness_centrality',\n",
    "        'gs_betweenness_centrality_normed',\n",
    "        'sv_betweenness_centrality_normed',\n",
    "        'gs_degree',\n",
    "        'sv_degree',\n",
    "        'gs_strength',\n",
    "        'sv_strength',\n",
    "        '\"sv_duplicates\"',\n",
    "        '\"gs_duplicates\"',\n",
    "        # 'gs_only_pubs',\n",
    "        # 'sv_only_pubs',\n",
    "        # 'shared_pubs',\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "    writer.writeheader()\n",
    "    for row_dict in dict_list:\n",
    "        writer.writerow(row_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

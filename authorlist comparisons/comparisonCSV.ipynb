{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f4d72bc6-60c9-4877-b597-0566229d982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127f5bf5de20d338f686704a9a328b86\n"
     ]
    }
   ],
   "source": [
    "import os, sys, re, ast\n",
    "import csv\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from pybliometrics.scopus import CitationOverview, AuthorRetrieval, AbstractRetrieval\n",
    "from pybliometrics.scopus.utils import config\n",
    "config['Authentication'] ['APIKey'] = \"127f5bf5de20d338f686704a9a328b86\"\n",
    "print(config['Authentication'] ['APIKey'])\n",
    "import bct\n",
    "from scholarly import scholarly, ProxyGenerator\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9a23163e-670f-4469-9fec-4fdab2d88cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthor_matrix(df):\n",
    "    names = df.loc[:,\"Name\"]\n",
    "    coauthor_matrix = np.zeros((names.size, names.size))\n",
    "\n",
    "    for idx, author in df.iterrows():\n",
    "        auth_name = author[\"Name\"]\n",
    "        row = names[names == auth_name].index[0]\n",
    "        try:\n",
    "            coauthors = ast.literal_eval(author[\"Coauthors\"]) #get coauthors\n",
    "            if len(coauthors) == 0: print(auth_name, \"has no coauthors\")\n",
    "            for coauthor in coauthors.keys():\n",
    "                num_publications = coauthors[coauthor]\n",
    "                col = names[names == coauthor].index[0]\n",
    "                coauthor_matrix[col][row] += num_publications\n",
    "\n",
    "        except:\n",
    "            print(auth_name, \"has no coauthors\")\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    return coauthor_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d78ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_details(author_row, sv_df, gs_df) -> dict:\n",
    "    \n",
    "    #get scopus profile\n",
    "    sv_name = sv_df.at[author_row,\"Name\"]\n",
    "    sv_id = sv_df.at[author_row,\"Scopus ID\"]\n",
    "    sv_coauthors = sv_df.at[author_row,\"Coauthors\"]\n",
    "    ar = AuthorRetrieval(sv_id)\n",
    "    pubs = ar.get_documents()\n",
    "    \n",
    "    #get scopus publications\n",
    "    sv_titles = []\n",
    "    for pub in pubs:\n",
    "        sv_titles.append(pub.title)\n",
    "\n",
    "    #get gs profile\n",
    "    gs_name = gs_df.at[author_row,\"Name\"]\n",
    "    gs_id = gs_df.at[author_row,\"Scholar ID\"]\n",
    "    gs_coauthors = gs_df.at[author_row,\"Coauthors\"]\n",
    "    pg = ProxyGenerator()\n",
    "    success = pg.FreeProxies()\n",
    "    scholarly.use_proxy(pg)\n",
    "    author = scholarly.search_author_id(gs_id)\n",
    "\n",
    "    #get gs publications\n",
    "    gs_titles = []\n",
    "    data_dict = scholarly.fill(author, sections=['basics', 'indices', 'publications', 'counts'])\n",
    "\n",
    "    for pub in data_dict['publications']:\n",
    "        gs_titles.append(pub['bib']['title'])\n",
    "\n",
    "    #clean titles\n",
    "    sv_titles = [\n",
    "        title.replace(\"<sup>\",\"\").replace(\"</sup>\",\"\").replace(\"<inf>\",\"\").replace(\"</inf>\",\"\") \n",
    "        for title in sv_titles\n",
    "    ]\n",
    "        #clean\n",
    "    sv_titles = [\n",
    "        \" \".join(\n",
    "            [\n",
    "                word.strip() \n",
    "                for word in re.sub(r'[^\\w]', ' ', title.lower()).split(\" \") \n",
    "                if word != \"\"])\n",
    "        for title in sv_titles\n",
    "        ]\n",
    "    # gs_titles_lowered = [re.sub(r'[^\\w]', ' ', title.lower()).strip() for title in gs_titles]\n",
    "    gs_titles = [\n",
    "        \" \".join(\n",
    "            [\n",
    "                word.strip() \n",
    "                for word in re.sub(r'[^\\w]', ' ', title.lower()).split(\" \") \n",
    "                if word != \"\"])\n",
    "        for title in gs_titles\n",
    "        ]\n",
    "\n",
    "    total_gs_pubs = len(gs_titles)\n",
    "    total_sv_pubs = len(sv_titles)\n",
    "\n",
    "    #duplicates\n",
    "    sv_duplicates = [k for k,v in Counter(sv_titles).items() if v>1]\n",
    "    gs_duplicates = [k for k,v in Counter(gs_titles).items() if v>1]\n",
    "\n",
    "    #matching titles\n",
    "    shared_titles = list(set(gs_titles).intersection(sv_titles))\n",
    "    num_matches = len(shared_titles)\n",
    "    shared_str = ''\n",
    "    for title in shared_titles:\n",
    "        shared_str = title + \"\\n\" + shared_str\n",
    "\n",
    "    #only sv\n",
    "    sv_only_titles = list(set(sv_titles) - set(gs_titles))\n",
    "    sv_only_str = ''\n",
    "    for title in sv_only_titles:\n",
    "        sv_only_str = title + \"\\n\" + sv_only_str\n",
    "    num_sv_only = len(sv_only_titles)\n",
    "\n",
    "    #only gs\n",
    "    gs_only_titles = list(set(gs_titles) - set(sv_titles))\n",
    "    gs_only_str = ''\n",
    "    for title in gs_only_titles:\n",
    "        gs_only_str = title + \"\\n\" + gs_only_str\n",
    "    num_gs_only = len(gs_only_titles)\n",
    "\n",
    "    author_dict = {\n",
    "        'sv_name': sv_name, \n",
    "        'gs_name': gs_name, \n",
    "        'gs_count': total_gs_pubs, \n",
    "        'gs_duplicates_count':gs_duplicates,\n",
    "        'sv_count': total_sv_pubs, \n",
    "        'sv_duplicates_count':sv_duplicates,\n",
    "        'gs_only_count':num_gs_only, \n",
    "        'sv_only_count':num_sv_only,\n",
    "        'shared_count':num_matches,\n",
    "        'gs_coauthors':gs_coauthors,\n",
    "        'sv_coauthors':sv_coauthors,\n",
    "        'gs_betweenness_centrality_normed': \"\",\n",
    "        'sv_betweenness_centrality_normed': \"\",\n",
    "        # 'gs_only_pubs':gs_only_str,\n",
    "        # 'sv_only_pubs':sv_only_str,\n",
    "        # 'shared_pubs':shared_str,\n",
    "    }\n",
    "    return author_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7a9b5b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annie Vogel-Ciernia has no coauthors\n",
      "Mark S. Cembrowski has no coauthors\n",
      "Michael J. Gordon has no coauthors\n",
      "Manu S. Madhav has no coauthors\n",
      "Brian D. Fisher has no coauthors\n",
      "Emily Lauren Sylwestrak has no coauthors\n",
      "\n",
      "\n",
      "Michael Gordon has no coauthors\n",
      "Manu S Madhav has no coauthors\n",
      "Emily Sylwestrak has no coauthors\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# author_row = 6\n",
    "\n",
    "sv_df = pd.read_csv(\"scival_outputs/scival_authorlist_publications_official.csv\")\n",
    "gs_df = pd.read_csv(\"gs_outputs/gs_authorlist_publications.csv\")\n",
    "\n",
    "sv_coauthor_matrix = get_coauthor_matrix(sv_df)\n",
    "gs_coauthor_matrix = get_coauthor_matrix(gs_df)\n",
    "\n",
    "sv_betweenness = bct.betweenness_bin(sv_coauthor_matrix)\n",
    "sv_betweenness_normed = sv_betweenness/((len(sv_coauthor_matrix)-1)*(len(sv_coauthor_matrix)-2))\n",
    "\n",
    "gs_betweenness = bct.betweenness_bin(gs_coauthor_matrix)\n",
    "gs_betweenness_normed = gs_betweenness/((len(gs_coauthor_matrix)-1)*(len(gs_coauthor_matrix)-2))\n",
    "\n",
    "gs_degrees = bct.degrees_und(gs_coauthor_matrix)\n",
    "sv_degrees = bct.degrees_und(sv_coauthor_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4bb0dc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gs_betweenness_normed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d13c11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "for row in range(len(sv_df.index)):\n",
    "    author_dict = get_publication_details(row, sv_df, gs_df)\n",
    "    author_dict['gs_betweenness_centrality'] = gs_betweenness[row]\n",
    "    author_dict['sv_betweenness_centrality'] = sv_betweenness[row]\n",
    "    author_dict['gs_betweenness_centrality_normed'] = gs_betweenness_normed[row]\n",
    "    author_dict['sv_betweenness_centrality_normed'] = sv_betweenness_normed[row]\n",
    "    author_dict['gs_degree'] = gs_degrees[row]\n",
    "    author_dict['sv_degree'] = sv_degrees[row]\n",
    "    dict_list.append(author_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c098d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dict_list:\n",
    "    gs_num_duplicates = len(d['gs_duplicates_count'])\n",
    "    d.update((k, gs_num_duplicates) for k, v in d.items() if k == \"gs_duplicates_count\")\n",
    "    sv_num_duplicates = len(d['sv_duplicates_count'])\n",
    "    d.update((k, sv_num_duplicates) for k, v in d.items() if k == \"sv_duplicates_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0113aaaa-138d-410d-98b6-ae27521eeec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"authors_comparisons_realnumduplicates.csv\", \"w\") as csv_file:\n",
    "    header = [\n",
    "        'sv_name', \n",
    "        'gs_name', \n",
    "        'gs_count', \n",
    "        'gs_duplicates_count',\n",
    "        'sv_count', \n",
    "        'sv_duplicates_count',\n",
    "        'gs_only_count', \n",
    "        'sv_only_count',\n",
    "        'shared_count',\n",
    "        'gs_coauthors',\n",
    "        'sv_coauthors',\n",
    "        'gs_betweenness_centrality',\n",
    "        'sv_betweenness_centrality',\n",
    "        'gs_betweenness_centrality_normed',\n",
    "        'sv_betweenness_centrality_normed',\n",
    "        'gs_degree',\n",
    "        'sv_degree',\n",
    "        'gs_only_pubs',\n",
    "        'sv_only_pubs',\n",
    "        'shared_pubs',\n",
    "    ]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames = header)\n",
    "    writer.writeheader()\n",
    "    for row_dict in dict_list:\n",
    "        writer.writerow(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9e074-9e9a-48c2-adc1-0bfb351a76e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

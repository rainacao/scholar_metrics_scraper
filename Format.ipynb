{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DMCBH_MEMBERS_CSV = \"Copy of DMCBH member IRP categories_Aug2023.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_for_gs(member_arr):\n",
    "    gs_member_mask = [int(member_arr[i][8]) for i in range(len(member_arr))]\n",
    "    gs_member_arr = [member_arr[i] for i in range(len(member_arr)) if gs_member_mask[i] == 1]\n",
    "    print(f\"filtered from {len(member_arr)} members to {len(gs_member_arr)} members based on google scholar profile\")\n",
    "    return gs_member_arr\n",
    "\n",
    "def output_members(member_arr, out_path):\n",
    "    with open(out_path, \"w+\") as f:\n",
    "        # w = csv.writer(f)\n",
    "        for member in member_arr:\n",
    "            f.write(member+\"\\n\")\n",
    "\n",
    "def get_all_participation_names_only(member_array):\n",
    "    print(f\"getting members of the whole list...\")\n",
    "    members = []\n",
    "    for member_row in member_array:\n",
    "\n",
    "        firstname = member_row[1].strip()\n",
    "        lastname = member_row[0].strip()\n",
    "        search = f\"{firstname} {lastname}\"\n",
    "    \n",
    "        members.append(search)\n",
    "\n",
    "    print(members)\n",
    "    print(f\"there are {len(members)} members\\n\")\n",
    "\n",
    "    output_members(members,\"all_dmcbh_members-simplified.csv\")\n",
    "\n",
    "def get_all_participation(member_array):\n",
    "    print(f\"getting members of the whole list...\")\n",
    "    members = []\n",
    "    for member_row in member_array:\n",
    "\n",
    "        if member_row[10] != \"\":\n",
    "            #find using ID and force include\n",
    "            # print(\"adding ID\")\n",
    "            search = member_row[10]\n",
    "        else:\n",
    "            #find using name\n",
    "            firstname = member_row[1].strip()\n",
    "            lastname = member_row[0].strip()\n",
    "            search = f\"{firstname} {lastname}\"\n",
    "    \n",
    "        members.append(search)\n",
    "\n",
    "    print(members)\n",
    "    print(f\"there are {len(members)} members\\n\")\n",
    "\n",
    "    output_members(members,\"all_dmcbh_members.csv\")\n",
    "\n",
    "def get_irp_participation_names_only(colnum, cols, member_array):\n",
    "    print(f\"getting members of {cols[colnum]} IRP...\")\n",
    "    irp_members = []\n",
    "    for member_row in member_array:\n",
    "\n",
    "        firstname = member_row[1].strip()\n",
    "        lastname = member_row[0].strip()\n",
    "        search = f\"{firstname} {lastname}\"\n",
    "\n",
    "        irp_participation = member_row[colnum].strip()\n",
    "        if irp_participation == \"Primary\":\n",
    "            irp_members.append(search)\n",
    "\n",
    "    print(irp_members)\n",
    "    print(f\"{cols[colnum]} has {len(irp_members)} members\\n\")\n",
    "    \n",
    "    # out_path = f\"{cols[colnum]} IRP Members.csv\"\n",
    "    out_path = f\"all-{cols[colnum]}-simplified.csv\"\n",
    "    output_members(irp_members, out_path)\n",
    "\n",
    "def get_irp_participation(colnum, cols, member_array):\n",
    "    print(f\"getting members of {cols[colnum]} IRP...\")\n",
    "    irp_members = []\n",
    "    for member_row in member_array:\n",
    "\n",
    "        # firstname = member_row[1].strip()\n",
    "        # lastname = member_row[0].strip()\n",
    "        # search = f\"{firstname} {lastname}\"\n",
    "        \n",
    "        if member_row[10] != \"\":\n",
    "            #find using ID and force include\n",
    "            # print(\"adding ID\")\n",
    "            search = member_row[10]\n",
    "        else:\n",
    "            #find using name\n",
    "            firstname = member_row[1].strip()\n",
    "            lastname = member_row[0].strip()\n",
    "            search = f\"{firstname} {lastname}\"\n",
    "        \n",
    "        irp_participation = member_row[colnum].strip()\n",
    "        if irp_participation == \"Primary\":\n",
    "            irp_members.append(search)\n",
    "\n",
    "    # irp_members = [member_names[i] for i in range(len(member_names)) if member_array[i][colnum].strip() == \"Primary\"]\n",
    "    print(irp_members)\n",
    "    print(f\"{cols[colnum]} has {len(irp_members)} members\\n\")\n",
    "    \n",
    "    # out_path = f\"{cols[colnum]} IRP Members.csv\"\n",
    "    out_path = f\"{cols[colnum]}.csv\"\n",
    "    output_members(irp_members, out_path)\n",
    "\n",
    "def simplify_names(member_csv, ss_output_csv):\n",
    "    cleaned_names = []\n",
    "    with open(member_csv, \"r\") as m_file:\n",
    "        names = m_file.readlines()\n",
    "        cleaned_names = [name.strip() for name in names]\n",
    "        \n",
    "    df = pd.read_csv(ss_output_csv)\n",
    "    df[\"Name\"] = cleaned_names\n",
    "    # print(df.head())\n",
    "    #get indices of rows with warnings\n",
    "    #use iloc through all rows, update and turn everything after column 1 () into \"\"\n",
    "    df.to_csv(f\"simplified-{ss_output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify_names(\"Mental Health & Addictions-simplified.csv\", \"irp_mha_members_output_data.csv\")\n",
    "# simplify_names(\"Brain Injury & Repair-simplified.csv\", \"irp_bir_members_output_data.csv\")\n",
    "# simplify_names(\"Brain Development & Neurodevelopmental Disorders-simplified.csv\", \"irp_bdnd_members_output_data.csv\")\n",
    "# simplify_names(\"Learning Memory & Dementias-simplified.csv\", \"irp_lmd_members_output_data.csv\")\n",
    "# simplify_names(\"Sensory Motor Systems & Movement Disorders-simplified.csv\", \"irp_smsmd_members_output_data.csv\")\n",
    "# simplify_names(\"dmcbh_members-simplified.csv\", \"dmcbh_members_output_data.csv\")\n",
    "# simplify_names(\"all_dmcbh_members-simplified.csv\", \"all_dmcbh_members_output_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'simplified-all_dmcbh_members_output_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msimplified-all_dmcbh_members_output_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(len(df))\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# for i in range(len(df)):\u001b[39;00m\n\u001b[1;32m      4\u001b[0m no_gs_idx \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mindex[df[\u001b[39m\"\u001b[39m\u001b[39mWarning\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnotna()]\n",
      "File \u001b[0;32m~/miniconda3/envs/sms/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/sms/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/sms/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/envs/sms/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/sms/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'simplified-all_dmcbh_members_output_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"simplified-all_dmcbh_members_output_data.csv\")\n",
    "# print(len(df))\n",
    "# for i in range(len(df)):\n",
    "no_gs_idx = df.index[df[\"Warning\"].notna()]\n",
    "\n",
    "print(len(df.columns))\n",
    "\n",
    "for i in range(2, len(df.columns)):\n",
    "    df.iloc[no_gs_idx, i] = np.NaN\n",
    "    print(df.iloc[no_gs_idx, i])\n",
    "\n",
    "df.to_csv(\"cleaned-simplified-all_dmcbh_members_output_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. get array of all members from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "getting members of Mental Health & Addictions IRP...\n",
      "['Jehannine Austin', 'Steven Barnes', 'Alasdair Barr', 'Clare Beasley', 'Trisha Chakrabarty', 'Luke Clark', 'Adele Diamond', 'Stan Floresco', 'Sophia Frangou', 'Amani Hariri', 'Kamyar Keramatian', 'Raymond Lam', 'Donna Lang', 'Erin Michalak', 'Anthony Phillips', 'Heather Robertson', 'Christian Sch√ºtz', 'Jeremy Seamans', 'Evelyn Stewart', 'Robert Stowe', 'Sriram Subramaniam', 'Rebecca Todd', 'Tamara Vanderwal', 'Victor Viau', 'Daniel Vigo', 'Fidel Vila-Rodriguez', 'Catharine Winstanley', 'Todd Woodward', 'Lakshmi Yatham']\n",
      "Mental Health & Addictions has 29 members\n",
      "\n",
      "getting members of Brain Development & Neurodevelopmental Disorders IRP...\n",
      "['Douglas Allan', 'Vanessa Auld', 'Shernaz Bamji', 'Annie Ciernia', 'Ann-Marie Craig', 'Lauren Emberson', 'Daniel Goldowitz', 'Ruth Grunau', 'Kurt Haas', 'Tao Huan', 'Hee Yeon Im', 'Freda Miller', \"Timothy O'Connor\", 'Paul Pavlidis', 'Mahmoud Pouladi', 'Manon Ranger', 'Jessica Rosin', 'Jane Roskams', 'Kiran Soma', 'Alexander Weber', 'Janet Werker']\n",
      "Brain Development & Neurodevelopmental Disorders has 21 members\n",
      "\n",
      "getting members of Learning Memory & Dementias IRP...\n",
      "['Khaled Abd-Elrahman', 'Phil Barker', 'Mark Cembrowski', 'Max Cynader', 'Dean Foti', 'Liisa Galea', 'Julien Gibon', 'Sherri Hayden', 'Robin Hsiung', 'Wilfred Jefferies', 'Ujendra Kumar', 'Ian Mackenzie', 'Manu Madhav', 'Haakon Nygaard', 'Daniela Palombo', 'Steven Pelech', 'Catharine Rankin', 'Julie Robillard', 'Jason Snyder', 'Weihong Song', 'Lawrence Ward']\n",
      "Learning Memory & Dementias has 21 members\n",
      "\n",
      "getting members of Sensory Motor Systems & Movement Disorders IRP...\n",
      "['Doug Altshuler', 'Jason Barton', 'Neil Cashman', 'Silke Cresswell', 'Doris Doudet', 'Debbie Giaschi', 'Michael Gordon', 'Anthony Herdman', 'Shannon Kolind', 'Piotr Kozlowski', 'John Kramer', 'Charles Krieger', 'Cornelia Laule', 'Blair Leavitt', 'Duncan Leitch', 'David Li', 'Joanne Matsubara', 'Benjamin Matthews', 'Martin McKeown', 'Kota Mizumoto', 'Robert Molday', 'Orson Moritz', 'Joel Oger', 'Ipek Oruc', 'Jacqueline Quandt', 'Lynn Raymond', 'Vesna Sossi', 'Miriam Spering', 'Jon Stoessl', 'Roger Tam', 'Tony Traboulsee', 'Helen Tremlett', 'Carles Vilarino-Guell']\n",
      "Sensory Motor Systems & Movement Disorders has 33 members\n",
      "\n",
      "getting members of Brain Injury & Repair IRP...\n",
      "['Shelina Babul', 'Lara Boyd', 'Peter Cripton', \"Ryan D'Arcy\", 'Thalia Field', 'Ilker Hacihaliloglu', 'Brett Hilton', 'Judy Illes', 'Sarah Kraeutner', 'Teresa Liu-Ambrose', 'Brian MacVicar', 'Steven Miller', 'Hakima Moukhles', 'Tim Murphy', 'William Panenka', 'Alexander Rauscher', 'Mypinder Sekhon', 'Noah Silverberg', 'Terry Snutch', 'Wolfram Tetzlaff', 'Paul van Donkelaar', 'Naznin Virji-Babul', 'Yu Tian Wang', 'Cheryl Wellington', 'Christopher West']\n",
      "Brain Injury & Repair has 25 members\n",
      "\n"
     ]
    }
   ],
   "source": [
    "member_arr = []\n",
    "with open(PATH_TO_DMCBH_MEMBERS_CSV, \"r\") as f:\n",
    "    r = csv.reader(f)\n",
    "    for row in r:\n",
    "        if row[0] != \"\":\n",
    "            member_arr.append(row)\n",
    "\n",
    "# skip header rows\n",
    "member_arr = member_arr[2:]\n",
    "print(len(member_arr))\n",
    "\n",
    "# filter for google scholar\n",
    "# member_arr = filter_for_gs(member_arr)\n",
    "# print(len(member_arr))\n",
    "\n",
    "# columns of the DMCBH CSV file\n",
    "cols = ['Last Name','First Name','Member Type','Mental Health & Addictions','Brain Development & Neurodevelopmental Disorders','Learning Memory & Dementias','Sensory Motor Systems & Movement Disorders','Brain Injury & Repair','Google Scholar?','GS Link']\n",
    "\n",
    "# print(member_arr)\n",
    "# output IRP\n",
    "# get_irp_participation(7, cols, member_arr)\n",
    "# get_all_participation(member_arr)\n",
    "for i in range(3,8):\n",
    "    get_irp_participation_names_only(i, cols, member_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in member_arr:\n",
    "    first_name = row[1].strip()\n",
    "    last_name = row[0].strip()\n",
    "    full_name = f\"{first_name} {last_name}\"\n",
    "    row.insert(0, full_name)\n",
    "\n",
    "    while \"Secondary\" in row:\n",
    "        row[row.index(\"Secondary\")] = \"\"\n",
    "    while \"Secondary \" in row:\n",
    "        row[row.index(\"Secondary \")] = \"\"\n",
    "    while \"Primary\" in row:\n",
    "        row[row.index(\"Primary\")] = full_name\n",
    "    while \"Primary \" in row:\n",
    "        row[row.index(\"Primary \")] = full_name\n",
    "\n",
    "member_arr.insert(0, cols)\n",
    "df = pd.DataFrame(member_arr)\n",
    "df.to_csv(\"foo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(csv_file):\n",
    "    member_arr = []\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        r = csv.reader(f)\n",
    "        for row in r:\n",
    "            if row[0] != \"\":\n",
    "                member_arr.append(row)\n",
    "    return member_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmcbh_csv = \"all_dmcbh_members-simplified.csv\"\n",
    "bdnd_csv = \"Brain Development & Neurodevelopmental Disorders-simplified.csv\"\n",
    "mha_csv = \"Mental Health & Addictions-simplified.csv\"\n",
    "smsmd_csv = \"Sensory Motor Systems & Movement Disorders-simplified.csv\"\n",
    "lmd_csv = \"Learning Memory & Dementias-simplified.csv\"\n",
    "bir_csv = \"Brain Injury & Repair-simplified.csv\"\n",
    "\n",
    "irp_names = ['Name','Mental Health & Addictions','Brain Development & Neurodevelopmental Disorders','Learning/Memory & Dementias','Sensory/Motor Systems & Movement Disorders','Brain Injury & Repair']\n",
    "\n",
    "dmcbh_names = csv_to_list(dmcbh_csv)\n",
    "mha_names = csv_to_list(mha_csv)\n",
    "bdnd_names = csv_to_list(bdnd_csv)\n",
    "lmd_names = csv_to_list(lmd_csv)\n",
    "smsmd_names = csv_to_list(smsmd_csv)\n",
    "bir_names = csv_to_list(bir_csv)\n",
    "\n",
    "dmcbh_names_clean = [name[0] for name in dmcbh_names]\n",
    "\n",
    "mha = []\n",
    "bdnd = []\n",
    "lmd = []\n",
    "smsmd = []\n",
    "bir = []\n",
    "\n",
    "for name in dmcbh_names:\n",
    "    if name in mha_names:\n",
    "        mha.append(name[0])\n",
    "    else:\n",
    "        mha.append(\"\")\n",
    "    \n",
    "    if name in bdnd_names:\n",
    "        bdnd.append(name[0])\n",
    "    else:\n",
    "        bdnd.append(\"\")\n",
    "    \n",
    "    if name in lmd_names:\n",
    "        lmd.append(name[0])\n",
    "    else:\n",
    "        lmd.append(\"\")\n",
    "\n",
    "    if name in smsmd_names:\n",
    "        smsmd.append(name[0])\n",
    "    else:\n",
    "        smsmd.append(\"\")\n",
    "\n",
    "    if name in bir_names:\n",
    "        bir.append(name[0])\n",
    "    else:\n",
    "        bir.append(\"\")\n",
    "\n",
    "\n",
    "grouped_names_dict = {\n",
    "    'Name': dmcbh_names_clean,\n",
    "    'Mental Health & Addictions': mha,\n",
    "    'Brain Development & Neurodevelopmental Disorders': bdnd,\n",
    "    'Learning/Memory & Dementias': lmd,\n",
    "    'Sensory/Motor Systems & Movement Disorders': smsmd,\n",
    "    'Brain Injury & Repair': bir,\n",
    "    }\n",
    "\n",
    "\n",
    "for key in grouped_names_dict:\n",
    "    print(len(grouped_names_dict[key]))\n",
    "\n",
    "grouped_df = pd.DataFrame.from_dict(grouped_names_dict)\n",
    "print(grouped_df.head())\n",
    "csv_file = \"grouped_irp_names.csv\"\n",
    "grouped_df.to_csv(csv_file)\n",
    "# try:\n",
    "#     with open(csv_file, 'w') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=irp_names)\n",
    "#         writer.writeheader()\n",
    "#         for data in dict_data:\n",
    "#             writer.writerow(data)\n",
    "# except IOError:\n",
    "#     print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
